Reviewer #3
Questions 3. Novelty
No new problem, solution, implementation or evaluation
5. Summary of contribution (in a few sentences)
The paper proposes an event sequence embedding method. Specifically, the paper proposes to adopt the idea of contrastive loss to train the embedding models. The method assumes that the subsequences sampled from the same sequence are generated from the same distribution and therefore can be paired as a positive example. And the embedding algorithm tries to maximize the distance between subsequences sampled from two different sequences. The experimental evaluation is done by applying the proposed method to real-world scenarios.
6. Describe in detail all strong points, labeled S1, S2, S3, etc.
S1. The paper clearly describe the assumption and the proposed techniques.
S2. The idea of using contrastive loss for learning sequence embedding in an unsupervised way is valid.
S3. The experimental evaluation is conducted in real-world scenarios and has discussion on several use cases.
7. Describe in detail all opportunities for improvement, labeled O1, O2, O3, etc.
 
O2. The heuristic/assumption this paper has for labeling the similar/dissimilar sequence is questionable. Specifically, 1) in practice, many sequences in the dataset behave similarly. It is risky to maximize the distance between two subsequences just because that they belong to different sequences. 2) Even within the same sequence, there may be local patterns. Local patterns may come from different distribution. It is unclear to me if the good performance is the result of a particular usecase or dataset. This needs to be properly addressed.
O3. The presentation can be improved.
1) The phrase 'positive pair' is mentioned early on in the paper without explanation. 2) Contribution 'real-word' -> 'real-world'
O4. It is unclear to me if this is the right venue for the work. It falls into the AI/ML topic. But it is not data intensive. RNN/LSTM/GRU does not scale well.
8. Please rank the three most critical strong points and/or opportunities for improvement that led to your overall evaluation rating, e.g., "{S1, O7, O4}"
O1, O2, S2
 
 9. Inclusive writing: does the paper follow the SIGMOD inclusive writing guidelines with respect to language, examples, figures? Please provide suggestions to the authors on how to improve the writing of the paper according to the guidelines.
The paper follows the SIGMOD inclusive writing guidelines with respect to language, examples, figures.
13. List required changes for a revision, if appropriate, by identifying subset of previously specified opportunities for improvement (e.g., O1, O3, O6).
O1, O2, O3


Reviewer #4
Questions 3. Novelty
Novel solution to existing problem
5. Summary of contribution (in a few sentences)
This paper focuses on the discrete event sequence modeling problem and proposes to use contrastive learning to learn embedding vectors for the event sequence in a self-supervised manner so that the embedding vectors can be used in downstream prediction tasks. Specifically, the learning signal is obtained by constructing positive and negative subsequence pairs, by sampling subsequences from the same sequence and difference sequences respectively. For each subsequence, each event will be encoded into a vector via embedding layers first, and then, an RNN-based encoder will be used to encode the event sequence into one compact vector for further contrastive training/fine-tuning. Experiments on both open datasets and commercial applications show promising results.
6. Describe in detail all strong points, labeled S1, S2, S3, etc.
S1. Well formulated problem with clear motivation. S2. Easy to follow, and results are good.
7. Describe in detail all opportunities for improvement, labeled O1, O2, O3, etc.
O1. Writing needs improvement. There are typos (mainly in sec 3.2, sec 4.1.2) and grammar errors here and there; The introduction is well written and clear, while the formulation part is badly written where the discussion is not clear (sec 3.3 batch generation and pairwise distance calculation).
O2. In Sec 3.2 subsequence random sampling algorithm, the descriptions of the three steps are not consistent with Algorithm 1. Why use continuous slice? although this paper also shows results of other sampling methods, the one used is not well justified and is too naive to be ideal. Why not directly sample T_i from [m, M]? Algo 1 can be simplified?
O3. In Sec 3.3 model training, again, the method being used is kind of naive and should test out more alternatives. and why ‘perform normalization of the embedding vectors' can makes 'this procedure more computationally effective'?’
O4. In Sec 3.4 encoder. the sequence encoder ‘use the recurrent network (RNN) similarly to [30]’, which should try out more design choices. Although in tab 1, this paper actually uses GRU and LSTM, options like BRNN, transformer (self-attention), etc are good alternatives to consider.
O5. In experiments. it is not clear whether the gain comes from the proposed self-supervised method, as in tab 4, very simple hand-crafted features can achieve very competitive results, which is actually better than the majority of the self-supervised baselines adopted.
8. Please rank the three most critical strong points and/or opportunities for improvement that led to your overall evaluation rating, e.g., "{S1, O7, O4}"
O1 O2 O3 O4 O5
9. Inclusive writing: does the paper follow the SIGMOD inclusive writing guidelines with respect to language, examples, figures? Please provide suggestions to the authors on how to improve the writing of the paper according to the guidelines.
yes
 
 13. List required changes for a revision, if appropriate, by identifying subset of previously specified opportunities for improvement (e.g., O1, O3, O6).
O1-O5


Reviewer #5
Questions 3. Novelty
Novel application of existing solution to a new problem
5. Summary of contribution (in a few sentences)
This paper presents CoLES, a contrastive learning method for analyzing event sequences. Contrastive learning enables CoLES to learn sequence representations where similar event sequences are close in the representation space. The authors conducted experiments on both public and in-house event sequence datasets and CoLES achieves significant improvement against baseline self-supervised learning methods.S1: this paper is well-written and easy to follow. All technical sections are presented in detail with sufficient illustrations.
S2: The experiments contain evaluation on both public event sequence datasets and real in-house datasets in finance.
S3: The improvement against baseline methods is quite significant.
6. Describe in detail all strong points, labeled S1, S2, S3, etc.
S1: this paper is well-written and easy to follow. All technical sections are presented in detail with sufficient illustrations.
S2: The experiments contain evaluation on both public event sequence datasets and real in-house datasets in finance.
S3: The improvement against baseline methods is quite significant.
7. Describe in detail all opportunities for improvement, labeled O1, O2, O3, etc.
O1 [motivation]: The presentation of this paper can benefit from a better positioned motivating example of CoLES. The first paragraph of the introduction mentions sharing transaction sequences across organization divisions as a motivating scenario. However, related issues such as data privacy or domain adaptation are not the main contributions of CoLES. I think the improved representation quality is the main focus instead. I think the authors can present a motivating example based on a real-world data science application on analyzing event sequences and discuss why we need better representations. I think this example can be followed by the discussion of why representation learning methods from CV or NLP are not expected to do well for event sequences.
O2 [novelty]: The contrastive learning techniques introduced in this paper seem quite standard. I think there are many other design choices that can be taken. For example, for data augmentation, one can take non- consecutive subsequences instead of consecutive ones. Similarity functions other than euclidian distance are also possible. It will be nice if the authors can discuss these changeable parts and potential design choices.
O3 [experiment]: The experiment section can benefit from having an ablation study. It is interesting to understand the effectiveness of the data augmentation technique compared to other possible designs, the choice of representation models, and the loss functions. A potential baseline for the loss function can be the one used in SimCLR.
8. Please rank the three most critical strong points and/or opportunities for improvement that led to your overall evaluation rating, e.g., "{S1, O7, O4}"
 
S2, O1, S1
9. Inclusive writing: does the paper follow the SIGMOD inclusive writing guidelines with respect to language, examples, figures? Please provide suggestions to the authors on how to improve the writing of the paper according to the guidelines.
I think this paper follows the SIGMOD's guidelines
11. Additional remarks. Use this field to describe remarks that are not critical strong points or opportunities for improvement, e.g., to highlight typos, formatting problems, or minor technical issues. In Section 4.0.1, it will be nice if there can be a table summarizing the dataset statistics.
13. List required changes for a revision, if appropriate, by identifying subset of previously specified opportunities for improvement (e.g., O1, O3, O6).
O1, O2


Reply:

We are very grateful for your attentive reading and detailed comments.

We would like to emphasize important points of our paper: The domain of event sequences is very important in a wide range of business applications, including finance, online services, e-commerce, recommender systems, telecom, etc. Before our work, there was no evidence that any self-supervised learning methods can show superiority in the complex event sequences domain. We implemented our method in one European bank, and it already brings hundreds of millions of dollars yearly.

We address opportunities for improvement below:

Reply to the Reviewer #3:

O1:

In Section 4, we consider four alternative self-supervised targets, namely, the next sequence prediction task used , sequence order prediction task, replaced token detection, and next event embedding prediction (CPC) (see Section 4.1.3). As shown in Table 3 and 4, CoLES significantly outperforms other self-supervised methods in both scenarios (unsupervised embeddings and fine-tuning).

We will include the suggested paper to the related work section.

O2:

We made this assumption based on that adding the negative penalty for close embeddings of other entities is the typical approach in contrastive learning in other domains e. g. the domain of images or speech. The main purpose of the negative penalty is to prevent mode collapse when all entities are placed at the same point in the embedding space.
In the experiments section, we consider 4 completely different publicly available datasets. As shown in Tables 3 and 4, our approach significantly outperforms alternative self-supervised methods where negative samples are not used in the loss function.

O4:

We applied scaling techniques for our method in several ways. First, the inference of RNN (or any other network) scales horizontally by partitioning input data e.g. by user IDs and processing different users on different hosts. We used Apache Spark on top of the Hadoop cluster for the horizontal scaling.
In our experiments on huge datasets described in Section 4.3, we used only part of the available client data for the training (10 million corporate clients, and 5 million individual clients), but applied the trained model to the all available transactional data which were more than 90 million cards in total.

We will add more details about the large-scale experiments to Section 4.3 in the revised paper.

Reply to the Reviewer #4

O2:

One practical motivation of using the continuous slices instead of direct sampling from T_i is that we want to preserve some small patterns of events e.g. frequent pairs of events in the sampled subsequences. Also, it is possible to show that for the proposed algorithm, the distribution of the generated sub-sequences is close to the initial distribution of sequences in some realistic assumptions. We have not included the detailed theoretical analysis of that fact due to the limitations of the paper size. We will try to add more details  in the revised paper.

Also, as shown in Table 2, the proposed algorithm performs significantly better than the other alternatives.

O3:

As we briefly mentioned in Section 4.2.1, we evaluated several possible loss functions and found that even the basic variant of contrastive learning loss, performs on par with the other losses. We will add the results of the comparison of different losses in the revised version of the paper.

For the normalized vectors, the squared Euclidean distance can be represented as 2(1- dot(X, Y)), hence, normalization allows to slightly optimize the calculations. We'll clarify that in the revised paper. 

O4:

As we mentioned in Section 4.3.1, the usage of GRU architecture allows to easily update an embedding of the already processed sequence when new events arrive. It is enough to initialize the GRU hidden state by the current version of embedding and process only the new events without reprocessing the whole sequence.

We also did the ablation study and compared the GRU with other options including a Transformer encoder, but had to remove the results due to the paper size limitations. We will add more details in the revised paper.

O5:

The proposed method consistently outperforms other self-supervised baselines for nearly all considered datasets. Simple hand-crafted features can achieve competitive results if the events have a clear structure for designing them. E.g. it is easy to calculate some aggregate statistics per MCC code for the card transactions history. In the commercial settings (which we consider in Section 4.3) we've seen different situation: it was hard to develop effective hand-crafted features for the transactions of the legal entities since it is not clear how they can be grouped. We discuss the difference between simple events (card transactions) and more complex events (transactions of the legal entities) at the end of Section 4.3. Unfortunately, we did not find a publicly available dataset with a significant enough complexity of the events and have to present results on the more simple datasets.

Reply to the Reviewer #5

O1:

In Section 4.3 we briefly present the real-world scenario of analyzing commercial transactions of the legal entities in a large European financial services company. We can not share publicly any data or subtle details on that experiment. Hence, we resorted to the publicly available datasets which are significantly smaller and contain rather simple sequences of events.

O2, O3:

We briefly describe some of the possible design choices and their impact in Section 4.2.1. We compared the proposed augmentation strategy with two alternatives and present the results in Table 2.

We also did the ablation study and considered other design choices, including different encoder architectures, different types of losses, and negative sampling. But we did not include it due to the paper size limitations. We will add a more detailed ablation study to the revised paper.



Meta-Reviewer:
Thank you for your submission to SIGMOD 2022. We received the reviews for your manuscript from the reviewers as well as your author feedback in response. After careful discussion, we decided to ask for a major revision. We encourage you to revise your paper taking into consideration the reviewer comments, and submit an improved version of the manuscript. Major revision items are summarized below. Please note that authors are allowed one extra page to help address reviewer comments in the revised version.

Major Revision Items:

1. State the training objective more clearly (Reviewer3 O1).

2. Address reviewers' common concern on the critical assumption made about sequences' data distributions and its impact on the approach's applicability to other datasets in general (Reviewer3 O2, as also voiced by the others).

3. Evaluate scalability under data-intensive settings (Reviewer3 O4).

4. Strengthen the motivation with a real-world data science application, emphasizing data management challenges where applicable (Reviewer5 O1).

5. Provide a more comprehensive discussion on design choices and add a more detailed ablation study to the experimental evaluation (Reviewer5 O2 and O3).

6. Fix all presentation issues and improve writing clarity as suggested across all three reviews.



Revised paper cover letter

We significantly revised the paper according to the reviewers comments. We've made the following updates in the revised version of the paper:

We've updated the Section 3.2 and Section 3.3 to make training objectives and subsample generation algorithm more clear.

Please note that we address the critical assumption made about sequences' data distributions in the following way: In Section 4.0.2 we measure the KL-divergence between two kinds of samples: (1) between random slices of the same sequence, generated using a modified version of the Algorithm 1 where overlapping events are dropped and (2) between random sub-samples taken from different sequences. We show that for all consdered dataset the mean KL-divergence is significantly smaller than for the textual data, which does not have periodicity and repeatability properties.

We've extended Section 4.3.1 and described the scalability approaches used during the deployment of our method in our organization

We've rewritten the introduction and made more clear statements about the benefits of using sequence embeddings for the real-word scenarios of bigdata analysis and predictive modelling.

We've updated the Section 4.2.1 and added additional experiments comparing desing choices of the method with possible alternatives.

We've also tested our method on the additional credit scoring dataset, which is the larges public dataset available for the transactional data. We show that self-supervised embeddings can be significantly better than the hand-crafted features on the sufficiently large dataset.

We've fixed different presentation issues and additionally proof-read the paper

The significant changes made to the paper are outlined in magenta.
